import ngram, subprocess
class SvmLiteWrapper:
    
    '''
    SVMLite calls:
    svm_learn example1/train.dat example1/model
    svm_learn [training file] [output file]

    svm_classify example1/test.dat example1/model example1/predictions
    svm_classify [test file] [training model] [output file]
    '''


    def __init__(self, n, deceptive_list_list, truthful_list_list):
        #Generate truthful and deceptive ngrams
        self.n = n
        self.truthful_ngrams = []
        for review in truthful_list_list:
            self.truthful_ngrams.append(ngram.Gram(n, review, 0))

        self.deceptive_ngrams = []
        for review in deceptive_list_list:
            self.deceptive_ngrams.append(ngram.Gram(n, review, 0))
        
        #Map ngrams to their ids. If this is slow, use a hashing function instead
        self.id_map = self.gen_id_map()


    
    def gen_id_map(self):
        #Start count at 2. Count = 1 implies unknown ngram
        count = 2
        id_map = dict()
        for gram in self.deceptive_ngrams:
            for k in gram.dictionary.keys():
                if id_map.has_key(k):
                    continue
                else:
                    id_map[k] = count
                    count += 1
        for gram in self.truthful_ngrams:
            for k in gram.dictionary.keys():
                if id_map.has_key(k):
                    continue
                else:
                    id_map[k] = count
                    count += 1
        return id_map

    def get_id(self, gram):
        if self.id_map.has_key(gram):
            return self.id_map[gram]
        return 1

    def learn(self, model_location="svm_model.txt"):
        #This will generate a text file learning model in SVM format
        #Check to see if model already exists before re-generating it (bool param)
        self._gen_train_file(self.deceptive_ngrams, self.truthful_ngrams)
        c = str(10.**(-3.))
        #Then call svm_learn.exe
        #args = ['svm_learn.exe', ("-c "+c), "ngram_svm.txt", model_location]
        args = ['svm_learn.exe', "ngram_svm.txt", model_location]
        subprocess.call(args)
        print("Done generating SVM")
        return


    #Writes a text file that will be used for the training model
    def _gen_train_file(self, deceptive_ngrams, truthful_ngrams):
        #This will generate the training txt file
        #For each truthful example
        #target = 1
        #Feature list is list of "getid(feature):count(feature)"
        file_lines = []
        for gram in deceptive_ngrams:
            line = "-1"
            for (id, count) in self._features_from_ngram(gram):
                line += (" " + str(id) + ":" + str(count))
            file_lines.append(line)
        for gram in truthful_ngrams:
            line = "1"
            for (id, count) in self._features_from_ngram(gram):
                line += (" " + str(id) + ":" + str(count))
            file_lines.append(line)
        #print(file_lines)
        
        f = open("ngram_svm.txt",'w')
        for l in file_lines:
            f.write(str(l)+'\n')
        f.close()

    def _gen_test_file(self, grams):
        #This will generate the training txt file
        #For each truthful example
        #target = 1
        #Feature list is list of "getid(feature):count(feature)"
        file_lines = []
        for gram in grams:
            line = "0"
            for (id, count) in self._features_from_ngram(gram):
                line += (" " + str(id) + ":" + str(count))
            file_lines.append(line)
        
        f = open("ngram_svm_test.txt",'w')
        for l in file_lines:
            f.write(str(l)+'\n')
        f.close()
        
    def _features_from_ngram(self, model):
        lst = []
        unknown = 0 #Number of unknown ngrams in testing
        total = 0
        for k in model.dictionary.keys():
            id = self.get_id(k)
            count = model.get_count(k)
            if id == 1:
                total += 1
                unknown += 1
                continue
            total += count
            lst.append((id,count))
        if unknown>0:
            lst.append((1, unknown))
        #Sort by ids
        lst.sort(_compare)
        normalized = []
        for (i,c) in lst:
            normalized.append((i, (float(c) / float(total))))
        return normalized

    def classify(self, test_list_list, train_model_location="train_model.txt", test_model_location="test_model.txt"):
        #Generate ngram list for each test review
        ngrams = []
        for review in test_list_list:
            ngrams.append(ngram.Gram(self.n, review, 0))
        #Convert to svm format using your own function or self._gen_train_file(test_ngram_list, [])
        self._gen_test_file(ngrams)
        #Call svm_classify.exe
        args = ["svm_classify.exe", "ngram_svm_test.txt", "svm_model.txt", "classified.txt"]
        subprocess.call(args)
        #Read output file generated by svm_classify
        f = open("classified.txt").readlines()
        results = []
        scores = []
        for line in f:
            line=float(line)
            scores.append(line)
        scores.sort()
        median = scores[len(scores) / 2]
        #median = 0.
        print("Median: " + str(median))
        for line in f:
            line=float(line)
            if line>median:
                results.append(1)
            else:
                results.append(0)
        #Return list of results
        #Integration with deception.py is virtually identical to knn's integration with deception.py
        return results

def _compare(x,y):
    if x[0] > y[0]:
        return 1
    elif x[0] < y[0]:
        return -1
    return 0

